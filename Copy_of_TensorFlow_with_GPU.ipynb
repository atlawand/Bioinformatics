{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TensorFlow with GPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atlawand/Bioinformatics/blob/master/Copy_of_TensorFlow_with_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha6Sn67bjxQV"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuWvHPM8j5dS"
      },
      "source": [
        "#Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73,67,43],\n",
        "                   [91,88,64],\n",
        "                   [87,134,58],\n",
        "                   [102,43,37],\n",
        "                   [69,96,70]], dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHYPUwp5keAd"
      },
      "source": [
        "#Target (apples, oranges)\n",
        "targets = np.array([[56,70],\n",
        "                    [81,101],\n",
        "                    [119,133],\n",
        "                    [22,37],\n",
        "                    [103,119]], dtype= 'float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp0uS6ARlBSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd59995d-e4d4-425d-ba72-77b25378539a"
      },
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w2nl4X2lyBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2405bc-5236-47b8-92c3-cca44eab48d6"
      },
      "source": [
        "#Intialize weights and biases\n",
        "w = torch.randn(2,3, requires_grad=True)\n",
        "b = torch.randn(2,requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9050,  0.5896,  0.0866],\n",
            "        [ 1.0580, -0.0417, -0.3401]], requires_grad=True)\n",
            "tensor([-1.4877, -1.6675], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CroW1oHOmq5b"
      },
      "source": [
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc5rB3xSnV7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7188f94-0169-466d-c3f6-6f73f365f157"
      },
      "source": [
        "#Generate Predictions\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[107.8060,  58.1464],\n",
            "        [138.2964,  69.1722],\n",
            "        [161.2797,  65.0634],\n",
            "        [119.3809,  91.8683],\n",
            "        [123.6225,  43.5231]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5YuHAQSnmMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ff9e6d-41b5-49d8-8d0a-5bb84a2809d9"
      },
      "source": [
        "# compare with targets\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My3xkbCln294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64f4666-3a7a-4b32-8575-f1424a2266b3"
      },
      "source": [
        "diff = preds - targets\n",
        "torch.sum(diff*diff)/diff.numel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3213.8833, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzpNdSTOpcTU"
      },
      "source": [
        "#MSE (mean square error)\n",
        "def mse(t1,t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff*diff)/diff.numel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BED16dG7pxmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9572a7-8bd3-4e6f-e509-c0e31277802c"
      },
      "source": [
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3213.8833, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07eet8ptqQSb"
      },
      "source": [
        "#Compute Gradients\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z5qMwWErKrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3ac9c7-6dac-48f9-9601-99a22ffcb178"
      },
      "source": [
        "print(w)\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9050,  0.5896,  0.0866],\n",
            "        [ 1.0580, -0.0417, -0.3401]], requires_grad=True)\n",
            "tensor([[ 4805.9888,  4069.1392,  2678.7026],\n",
            "        [-1856.6931, -3516.9980, -1948.0527]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df-fGmAZrd2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53f6c84-e70e-469a-de05-b0ab54bd61ac"
      },
      "source": [
        "print(b)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.4877, -1.6675], requires_grad=True)\n",
            "tensor([ 53.8771, -26.4453])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UmfP2pAri1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec20cfa5-1a38-444c-b8d9-cdd6c249dd4e"
      },
      "source": [
        "print(w)\n",
        "w.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9050,  0.5896,  0.0866],\n",
            "        [ 1.0580, -0.0417, -0.3401]], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4805.9888,  4069.1392,  2678.7026],\n",
              "        [-1856.6931, -3516.9980, -1948.0527]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-HHFW-byn_Q"
      },
      "source": [
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5\n",
        "  b -= b.grad * 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS1TOpI70hDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0217064f-f2df-47ce-db03-6e41f191a0eb"
      },
      "source": [
        "w, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.8089,  0.5082,  0.0330],\n",
              "         [ 1.0951,  0.0287, -0.3011]], requires_grad=True),\n",
              " tensor([-1.4888, -1.6669], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDsF7b2Nzluc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a0ba41-6154-4e7f-a3a8-4b003548f8b4"
      },
      "source": [
        "print(w)\n",
        "w - w.grad * 1e-5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.8089,  0.5082,  0.0330],\n",
            "        [ 1.0951,  0.0287, -0.3011]], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7608,  0.4676,  0.0062],\n",
              "        [ 1.1137,  0.0638, -0.2817]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6KoY3gtzywZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa57f7f3-9a6a-448c-84d3-484059c53c28"
      },
      "source": [
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2117.1353, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvSlo3HT1QfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb5ae2e-518c-40e7-f4ba-d71151485d07"
      },
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "230c8c7a-13fd-46b3-c5b1-9c6330cfd846"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "bb32a619-b9f8-4866-fe6a-40d8c5341e7e"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.862475891000031\n",
            "GPU (s):\n",
            "0.10837535100017703\n",
            "GPU speedup over CPU: 35x\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}